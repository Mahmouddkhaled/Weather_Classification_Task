{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd574f3-bef1-4c31-900a-8c7b35994710",
   "metadata": {},
   "source": [
    "<center> <h3> Weather Classification Task - Mahmoud Khaled </h3> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76c7868-406b-46f1-8bb6-b44c68ab3a5a",
   "metadata": {},
   "source": [
    "#### Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7fbf5-694b-4b9e-844a-62fa34ca4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings #ignore warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e03170-f6aa-4a9c-9e8e-21bd40ab5f12",
   "metadata": {},
   "source": [
    "### Data Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb1609-29c4-4fdb-83b3-ab69fea235d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"weatherAUS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c076f-0c7c-4f0e-86ce-06fcb8ee67d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9069ac-2e7c-44a8-9d91-b8546cd776a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15cb86-322c-471b-bddc-775e81e7e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a3cda-17bb-4d59-b588-a57de03dfc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9636ed0-fa32-4309-9f3b-326c7213ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicated records\n",
    "df.drop_duplicates(keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d7868a-6921-4673-b913-c9f7f5b476a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the dates which currently coded as strings into datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78364166-17e4-4975-beb1-2592d16f670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Year'] = df['Date'].dt.year          # extract year (I think it is not important like month in terms of weather) - convert to comment not run\n",
    "df['Month'] = df['Date'].dt.month          # extract month\n",
    "df['Month'] = df['Month'].astype('object') # You should add Month as object\n",
    "# df['Day'] = df['Date'].dt.day            # extract day (I think it is not important like month in terms of weather) - convert to comment not run\n",
    "df.drop(columns = ['Date'], inplace = True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f73a997-d823-4e25-8ff6-59699264c14a",
   "metadata": {},
   "source": [
    "##### Categorical and Numerical Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22860098-2725-440f-a80b-f9ef1a7a5eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Categorical_Features = df.select_dtypes(include = ['object']).columns.tolist() # list the categorical features\n",
    "Numerical_Features = df.select_dtypes(include = ['int', 'float']).columns.tolist() # list the numerical features\n",
    "print('Categorical_Features are: ', Categorical_Features)\n",
    "print('Numerical_Features are: ', Numerical_Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f947e064-3c98-400f-9c9a-62c9ec9ff174",
   "metadata": {},
   "source": [
    "##### Check Inconsistency for all categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d7632d-b68b-4673-9f9d-0759f8928094",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Categorical_Features:\n",
    "    frequency_table = df[col].value_counts()\n",
    "    print(frequency_table)\n",
    "    print('--------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1f19c7-379a-481c-9e07-bbf17a5c98b9",
   "metadata": {},
   "source": [
    "##### Remove missing from the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbef048-40cd-4a57-9f7e-9bac3e2d927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing from the target variable\n",
    "df.dropna(subset = ['RainTomorrow'] , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9746a85-0d58-4406-a233-4f2c16d5fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b949eb-03ae-4d86-b9f2-fad8b3896b98",
   "metadata": {},
   "source": [
    "##### Descriptive Statistics of all Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47cf3b4-68b8-499d-8400-f5309599aeab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "round(df.describe().T, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe1d799-5925-40b6-ae90-649e3976cd0b",
   "metadata": {},
   "source": [
    "#### Ouliers Detection and Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e77d32d-7e26-464e-8822-6126fe27a091",
   "metadata": {},
   "source": [
    "##### BoxPlots for Numerical Features to check Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9661f8-a4b3-44c1-a931-5706469400de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style\n",
    "sns.set_style('dark')\n",
    "\n",
    "# Define the number of rows and columns for subplots\n",
    "rows = 6\n",
    "cols = 3\n",
    "\n",
    "# Create the subplots\n",
    "fig, axis = plt.subplots(rows, cols, sharey = True, figsize = (15, 7))\n",
    "fig.suptitle('Boxplots for all Numerical Features', size = 25)\n",
    "\n",
    "# Flatten the axes array for easy indexing\n",
    "axis = axis.flatten()\n",
    "\n",
    "# Loop through the columns list and plot boxplots\n",
    "for i, feature in enumerate(Numerical_Features):\n",
    "    sns.boxplot(df[feature], orient = 'h', color = 'lightblue', ax = axis[i])\n",
    "    axis[i].set_title(feature)\n",
    "\n",
    "# Hide unused axes\n",
    "for j in range(i + 1, len(axis)):  # Starting from the next index of the last used axis\n",
    "    fig.delaxes(axis[j])  # Remove unused axes\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db76caba-0caa-457c-a729-364f086883d4",
   "metadata": {},
   "source": [
    "##### Outliers Treatment for all Numerical Features by Winsorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4dcf26-5151-4846-b6f5-5a581d4635eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Feature in Numerical_Features:\n",
    "    Q1,Q3 = np.nanpercentile(df[Feature], [25,75]) #or you can use ----->>     np.quantile(data , [0.25,0.75]\n",
    "    IQR = Q3 - Q1\n",
    "    lowerbound = Q1 - (1.5 * IQR)\n",
    "    upperbound = Q3 + (1.5 * IQR)\n",
    "    for i in df[Feature]:\n",
    "        if (i < lowerbound or i > upperbound):\n",
    "            if i > upperbound:\n",
    "                df.loc[(df[Feature] == i), Feature] = np.nanpercentile(df[Feature], 90)\n",
    "            elif i < lowerbound:\n",
    "                df.loc[(df[Feature] == i), Feature] = np.nanpercentile(df[Feature], 10)\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a265c9da-e9f6-4211-a87d-59622a242187",
   "metadata": {},
   "source": [
    "#### Missing Treatment by Average for Numerical and Mode for Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd610f2a-1090-422f-9dca-9f37c4f24565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can loop through all numerical variables\n",
    "for Feature in Numerical_Features:\n",
    "    df[Feature].fillna(value = df[Feature].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84cfc2-f1de-4ff5-a770-c0c6aeef71bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can loop through all categorical variables\n",
    "for Feature in Categorical_Features:\n",
    "    df[Feature].fillna(value = df[Feature].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac008e32-f99c-4e4a-b478-256a98a8d9bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c78d57-e20b-4264-b6bc-53d7e0f1ac7f",
   "metadata": {},
   "source": [
    "#### Data Splitting to X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58a29f-c1f8-45b9-aa8b-1d3b5118765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the target variable from feature variables\n",
    "X = df.drop(columns = ['RainTomorrow'])\n",
    "y = df['RainTomorrow']  # Ensure y is a 1D array\n",
    "# Relabel the 'RainTomorrow' column: 'yes' -> 1, 'no' -> 0\n",
    "y = df['RainTomorrow'].replace({'Yes': 1, 'No': 0})\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482efea0-f71b-488a-b90f-596ae476fab2",
   "metadata": {},
   "source": [
    "#### Data Transformation by ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5367596e-3aca-4496-84f6-cdd70d847ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder \n",
    "\n",
    "# Define categorical and numerical for only X Features\n",
    "Categorical_variables = X.select_dtypes(include = ['object']).columns.tolist() # list the categorical features\n",
    "Numerical_variables = X.select_dtypes(include = ['int', 'float']).columns.tolist() # list the numerical features\n",
    "\n",
    "\n",
    "# Define the transformers\n",
    "Numerical_transformer = MinMaxScaler()\n",
    "Categorical_transformer = OneHotEncoder(drop = 'first', handle_unknown = 'ignore')\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers = [('num', Numerical_transformer, Numerical_variables),\n",
    "                                                 ('cat', Categorical_transformer, Categorical_variables)])\n",
    "\n",
    "# Fit and transform the data\n",
    "Transformed_X = preprocessor.fit_transform(X).toarray()\n",
    "Transformed_X\n",
    "# Convert the result back to a DataFrame\n",
    "# Get feature names for the OneHotEncoded columns\n",
    "encoded_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(Categorical_variables)\n",
    "encoded_feature_names\n",
    "# Combine numerical and encoded categorical feature names\n",
    "feature_names = list(Numerical_variables) + list(encoded_feature_names)\n",
    "\n",
    "Transformed_X = pd.DataFrame(Transformed_X, columns = feature_names)\n",
    "\n",
    "# Now 'Transformed_X' contains both normalized numerical features and one-hot encoded categorical features\n",
    "Transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b958e-cd2d-4a57-8791-d9751c534bd3",
   "metadata": {},
   "source": [
    "##### Data Splitting to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562a15b-e6ec-48e4-894e-729ce3cd272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split            # split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ecddb7-4da9-45a3-9b37-18b88303db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, classification_report, roc_auc_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Transformed_X, y, test_size = 0.2, random_state = 1)\n",
    "Model = LogisticRegression(random_state = 1)\n",
    "Model.fit(X_train, y_train)\n",
    "y_pred = Model.predict(X_test)\n",
    "\n",
    "#Model Evaluation\n",
    "print('Sensitivity_score = ', recall_score(y_test, y_pred))\n",
    "print('Specificity_score = ', recall_score(y_test, y_pred, pos_label=0))\n",
    "print('Accuracy_score = ',accuracy_score(y_test, y_pred))\n",
    "print('Precision_score = ',precision_score(y_test, y_pred))\n",
    "print('F_score = ',f1_score(y_test, y_pred))\n",
    "print('-------------------------------------------------------------------')\n",
    "print('Classification Report')\n",
    "print('-------------------------------------------------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
